# Attention Models

Work in progress to implement both encoder/decoder attention and self
attention as seen in
[Attention is all You Need](https://arxiv.org/pdf/1706.03762.pdf).
